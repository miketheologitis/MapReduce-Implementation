{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f7c77d-25a0-4ddf-8d23-d5c967e93f6d",
   "metadata": {},
   "source": [
    "### Config\n",
    "\n",
    "Add to `/etc/hosts` the following:\n",
    "```\n",
    "127.0.0.1       datanode\n",
    "```\n",
    "\n",
    "We do this because the hadoop *namenode* (that we talk to for HDFS) returns the hostname of the datanode (i.e., `datanode`) but this returned hostname is inside the docker-compose network. This happens internally in the `kazoo` library hence this is the most straight-forward solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0837491-738f-4413-95f0-7505beac9e79",
   "metadata": {},
   "source": [
    "# Ecosystem\n",
    "\n",
    "Please use `light` theme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb6260-267a-4c40-a3c1-f90d83425b46",
   "metadata": {},
   "source": [
    "![system-architecture](images/docker_compose.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac512e35-7a4a-4892-8405-93c2cbe60fbf",
   "metadata": {},
   "source": [
    "We have a `docker-compose` network of many different services. They are all managed by `mapreduce.cluster.LocalCluster` using different `docker-compose` commands for different purposes (for instance, `.scale`, `.clear`, `.shutdown_cluster`, etc.). Moreover, as users we submit jobs to the system using `.mapreduce` and get back `concurrent.future`s, but more to that later... In order to use `LocalCluster` one must authenticate with `Auth` (just use `username`='admin', `password`='admin' ðŸ˜Š).\n",
    "\n",
    "The only requirement for the MapReduce system to work is accessible (`IP`, `PORT`) to `Zookeeper` and `HDFS` (in order to submit a job) and thats it!\n",
    "\n",
    "Services:\n",
    "\n",
    "1. `HDFS` : The Hadoop Distributed Filesystem, as the name suggests, works as a distributed Filesystem. The reason we chose `HDFS` is because we wanted to be able to effortlessly deploy it in a real cluster (asssumptions on a shared filesystem would make things more difficult in deployment).\n",
    "2. `Zookeeper` :  The `Zookeeper` service (replicated 3 times) is mainly used for its extremely helpful recipes. We found quite handy following:\n",
    "   1. Distributed Mutual Exclusion recipe\n",
    "   2. Setting up `Watcher` callbacks for different purposes (`ChildrenWatch` - watches for z-node children updates, `DataWatch` - watches for specific z-node data updates).\n",
    "   3. Distributed sequential ID generator recipe\n",
    "3. `Worker` : The workers perform the Tasks. We have three endpoints, i.e., `/map-task`, `/shuffle-task` and `/reduce-task`.\n",
    "4. `Master` : The masters, each able to handle MapReduce jobs in parallel (`threading`), are responsible for the proper execution of the Jobs. They send asynchronously `POST` requests to the workers' endpoints and wait for results. Moreover, they are responsible for the fault-tolerancy of the distributed system (handle `worker` deaths and other `master` deaths). Notably, the code for the masters is <ins>entirely</ins> `callbacks`. <ins>Things happen, and the master handles them accordingly</ins> (in coordination with other masters through Zookeeper recipes)! \n",
    "\n",
    "(Note: Yes, the `GIL` exists, but each master is I/O bound (spends most of the time waiting for things to happen). Hence, the `threading` is totally fine if not better than alternatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ef375-73e0-4562-bcbb-cdcd54b6951c",
   "metadata": {},
   "source": [
    "### ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c8184-a0ec-4f81-b6c0-d8038c7443bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/miketheologitis/MapReduce-Implementation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060c541-dc7d-479b-a3a0-c713f4b0b70b",
   "metadata": {},
   "source": [
    "### Authenticate\n",
    "\n",
    "Use the `Auth` in-between interface for fast authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395605e-8b4c-48c0-b9d6-cdb9a618553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreduce.authentication.auth import Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366073d2-4052-4fc7-a58a-ad5b09cdaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = Auth(username='admin', password='admin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5cfdd-844a-499d-96a4-e43e5995cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.is_authenticated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b9c10-7471-4b83-b1a9-a081253b7571",
   "metadata": {},
   "source": [
    "### Initialize the docker-compose network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d5727-362f-44ec-8ba8-ed27869e36ff",
   "metadata": {},
   "source": [
    "As mentioned before, we use `LocalCluster` as the docker-compose network management and job-submission service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624f769-d504-43d9-a0b5-e357b192642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreduce.cluster.local_cluster import LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ffb5d9-de1e-48ee-a348-ec6d270c6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(\n",
    "    auth=auth,\n",
    "    n_workers=4,\n",
    "    n_masters=1,\n",
    "    initialize=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6483eb-05dd-4cdc-9129-54b1609011f9",
   "metadata": {},
   "source": [
    "For sanity check, we can use `docker ps` in a terminal.\n",
    "\n",
    "The `LocalCluster` has a `LocalMonitoring` instance which has methods for printing the state of the cluster in a more beautiful manner.\n",
    "\n",
    "Let's use it and print the `Zookeeper` z-nodes current state and filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179415cb-c4bb-4c65-8bb4-681b8eeec231",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0edd30-aa68-411c-9079-cd2df42d5d5b",
   "metadata": {},
   "source": [
    "For HDFS (will contain nothing right now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566a752-bfce-4de9-8e1c-55ac4a457129",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_hdfs('jobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29049bda-9373-4cdc-ac5a-061910cf82f7",
   "metadata": {},
   "source": [
    "## MapReduce first job submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34577394-7599-40fe-b6d9-bee78f4ce46c",
   "metadata": {},
   "source": [
    "We need to first define the input data, the map function and the reduce function. The assumption is that the map-reduce functions follow the following:\n",
    "\n",
    "`map([x1, x2, ...]) -> [(k1, v2), (k2, v2), ...]`\n",
    "\n",
    "`reduce([v1, v2, ...]) -> y`\n",
    "\n",
    "where every element is arbitrary (any data structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50358ca5-6959-469a-9ba7-89880c1d0a98",
   "metadata": {},
   "source": [
    "Let's assume that our objective is to count how many times each character appears in the a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083245d-2856-4469-9920-90403c7ea20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['dasdsagf', 'mike', 'george', 'gertretr123', 'dsadsajortriojtiow']\n",
    "\n",
    "def map_func(data):\n",
    "    result = []\n",
    "    for string in data:\n",
    "        for char in string:\n",
    "            result.append((char, 1))\n",
    "    return result\n",
    "\n",
    "def reduce_func(data):\n",
    "    return sum(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55207d-e342-4ee0-b55c-0941428afaa3",
   "metadata": {},
   "source": [
    "For a quick sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815717ec-17ae-4bdc-970d-510caa8db833",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_func(['dasdsagf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516e80b-45f8-4276-8440-d1d67c0c0b5d",
   "metadata": {},
   "source": [
    "We are now ready to submit the job onto the MapReduce distributed system. We will use `.mapreduce` from `LocalCluster`. Note that we will return a `concurrent.futures` future object which represents a computation that hasn't necessarily completed yet. It's essentially a <ins>promise</ins> to hold the result of a computation that might still be ongoing - hence the name \"future\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570315f-73ed-41fd-921c-17e909404567",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = cluster.mapreduce(\n",
    "    data=data, \n",
    "    map_func=map_func, \n",
    "    reduce_func=reduce_func, \n",
    "    requested_n_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d2309-2e5e-4c2e-8290-af0268149397",
   "metadata": {},
   "outputs": [],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8772bb-b35f-40bc-bcaa-7f932f6dfe4d",
   "metadata": {},
   "source": [
    "Let's inspect what is happening behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87fdc7-b34f-402d-9fcd-a7f7bfdc3c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785fc3f-fa18-4da2-8302-28d4f8925b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_hdfs('jobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad2e1fe-4a6c-49ab-b0bd-08e6367f45ba",
   "metadata": {},
   "source": [
    "We can get the result of the computation using `.result()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4848a-1651-459c-912b-034d968326de",
   "metadata": {},
   "outputs": [],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c198a-c816-46ca-9651-22da54440b01",
   "metadata": {},
   "source": [
    "## Heavy-Load Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10357f9-bbdf-486e-a6aa-2ed49781fd0c",
   "metadata": {},
   "source": [
    "Let's submit the system to a lot of concurrent jobs and tasks. But, first we must scale the cluster. (Obviously, alive services are not impacted by this - they continue their tasks as normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a155d-6a77-4ab1-8865-fc90affee2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(\n",
    "    n_masters=3,\n",
    "    n_workers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf12cb-b86d-4bb7-8104-be4a8dcbe664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909e6e2-0cf4-4c42-a9cc-3e26527469a1",
   "metadata": {},
   "source": [
    "Let's create the same `data` list of strings but increase it in size a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de85d1-f2fe-454a-a893-f4da3bf65c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_string(str_len):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for _ in range(str_len))\n",
    "\n",
    "def generate_random_string_list(n, str_len):\n",
    "    return [generate_random_string(str_len) for _ in range(n)]\n",
    "\n",
    "# Generate 100k random strings of length 20\n",
    "data = generate_random_string_list(n=100_000, str_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70b360-6398-4cf4-82ec-2629f3ee76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac38c5-f50e-4a76-8ae5-f22a4918a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10e712-34d9-4136-a573-1e15f94deaba",
   "metadata": {},
   "source": [
    "Now it is time to submit a few jobs. We will submit the same `data`, `map_func` and `reduce_func` for ease. We will submit 10 such jobs and we expect the system to handle them concurrently. Note that us, as `host`, must upload the data (*map func*, *reduce* func, and *data*) onto HDFS so this is why the following will not finish immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e103e94-d2f1-429d-a42e-d7625db9f8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "futures = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Job {i+1} submitted.\", end='\\r')\n",
    "    future = cluster.mapreduce(data, map_func, reduce_func, requested_n_workers=2)\n",
    "    futures.append(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf99e40-6bc1-49b6-85e2-89411c174d14",
   "metadata": {},
   "source": [
    "We will print the futures to see if they are `running` or `finished`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c22f9-b604-4c50-b414-55955501e851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for future in futures:\n",
    "    print(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad797d24-6343-4c0a-bbd6-834bfb3dd5df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c07302-5100-4d2f-909d-58b32eddaa8e",
   "metadata": {},
   "source": [
    "Let's inspect some random results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5b970-0a20-4855-9c37-614dedcf35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures[1].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d295f-81d4-4b96-9099-a14a67f67b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6862ab2-0007-48d4-b197-d516c205367d",
   "metadata": {},
   "source": [
    "See all results per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4951940-1922-494f-ad9c-0898a5d26717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in zip(*[future.result() for future in futures]):\n",
    "    print(row)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16ab33-dd89-417e-be52-2ec950080b66",
   "metadata": {},
   "source": [
    "### Shutdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2933b-8aef-498c-a96d-5daaef99855f",
   "metadata": {},
   "source": [
    "Shutdown the cluster and cleanup the persistent HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7dafde-25d4-48ae-87fe-10d0b5778eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown_cluster(cleanup=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mapreduce] *",
   "language": "python",
   "name": "conda-env-mapreduce-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
