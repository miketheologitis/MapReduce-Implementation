{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c51c7b9-97d5-43ad-a264-80de500adec0",
   "metadata": {},
   "source": [
    "## Fault-Tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c3084-0a37-4eb6-af60-5b03d70fa739",
   "metadata": {},
   "source": [
    "One of the most important aspects of the MapReduce distributed system is fault-tolerance.\n",
    "\n",
    "If <ins>at all times at least one</ins> *master* service is alive, we guarantee fault tolerance for the following scenarios:\n",
    "1. *Worker* failures at any time.\n",
    "2. *Master* failures at any time.\n",
    "\n",
    "Our system not only guarantees fault-tolerance, but also that the computations in the event of *worker*, *master* failures will continue exactly where they left off as if nothing bad has happened. No recomputation will take place if not necessary. \n",
    "\n",
    "This notebook aims to simulate an extreme crisis situation in our MapReduce system: a perfect storm. Imagine a scenario where all the workers, in the midst of executing a MapReduce job, abruptly fail. As if this isn't catastrophic enough, the master responsible for coordinating that very job also shuts down unexpectedly, leaving a lone master as the sole survivor in our distributed system.\n",
    "\n",
    "Despite such a seemingly apocalyptic event, our system is designed to rise like a phoenix from the ashes. We will revive the system, scaling it back to full operation, and watch as it picks up the computation exactly where it left off, continuing towards successful completion as if the disaster never occurred. This notebook serves to demonstrate the robustness of our system, even when faced with the most severe challenges imaginable.\n",
    "\n",
    "Note: Addressing *worker* failures alone was comparatively simple. Likewise, overcoming *master* failures presented its unique challenges, that forced us to revise certain parts of our system. However, managing the simultaneous failures of both *workers* and *masters* - especially within the same job - has been an entirely different level of complexity. This scenario necessitates an extremely robust and meticulous system implementation. There are numerous intricate edge-cases that open the door for potential race condition issues. The system must not only handle failures independently but also efficiently coordinate and synchronize their concurrent occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c41753-36d9-45c9-88b6-1abda146f571",
   "metadata": {},
   "source": [
    "### Authenticate\n",
    "\n",
    "Use the `Auth` in-between interface for fast authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06e9e2-313f-4c95-b235-c7fc4be12bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreduce.authentication.auth import Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39643d7d-6aa3-4e01-a3c7-8291090d3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = Auth(username='admin', password='admin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb605d1-94e6-40f1-a10c-e6c404b64b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.is_authenticated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b495957-ee7e-4d81-a8c5-8c94863b8d44",
   "metadata": {},
   "source": [
    "### Initialize the docker-compose network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03cd190-8651-4659-b6f6-488da30aa38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreduce.cluster.local_cluster import LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b94bc63-d40f-4b74-aed9-b8760941dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(\n",
    "    auth=auth,\n",
    "    n_workers=4,\n",
    "    n_masters=2,\n",
    "    initialize=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613d63f-67bf-44cc-be2d-0f29069351f2",
   "metadata": {},
   "source": [
    "As in the previous notebook, let's assume that our objective is to count how many times each character appears in the a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e426411-51ab-41a1-9a86-772c963c48fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_func(data):\n",
    "    result = []\n",
    "    for string in data:\n",
    "        for char in string:\n",
    "            result.append((char, 1))\n",
    "    return result\n",
    "\n",
    "def reduce_func(data):\n",
    "    return sum(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d37652-592f-48bc-8522-4c2fc46f0146",
   "metadata": {},
   "source": [
    "Create some reasonable amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277cff9-b4d7-4d31-b386-6cf17073d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_string(str_len):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for _ in range(str_len))\n",
    "\n",
    "def generate_random_string_list(n, str_len):\n",
    "    return [generate_random_string(str_len) for _ in range(n)]\n",
    "\n",
    "data = generate_random_string_list(n=500_000, str_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97091033-6f84-4515-90fb-9486d5d20fef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26265a-4ab2-46b0-bc4e-ed9d4133dc50",
   "metadata": {},
   "source": [
    "### Kill workers amidst computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c730df-3299-4cfc-8b75-9e22fdb61860",
   "metadata": {},
   "source": [
    "This part (the next one aswell) will not be entirely sequential. We have configured `docker-compose` so that the *workers* and *masters* use the *container-id* as *hostname*. Hence, grab the 4 *worker* container-ids from bellow and prepare the `docker kill` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b94c4-a6fd-43c6-8d92-e20d43591e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706c9cd-b937-4da7-84e9-76709bf058c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_hdfs('jobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a98a2b-b843-4ba2-8f0b-c3be42d80bc0",
   "metadata": {},
   "source": [
    "Note, if `requested_n_workers` is not provided it defaults to `None` which is translated to the underlying computation as \"use as many workers as possible\".\n",
    "\n",
    "By now, you should have replaced the `docker kill` command with the appropriate ids from above (loaded our gun). We are ready to submit the job and kill the 4 workers on the spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b3824-1e97-465e-8935-a3c89e65296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "future = cluster.mapreduce(\n",
    "    data=data, \n",
    "    map_func=map_func, \n",
    "    reduce_func=reduce_func\n",
    ")\n",
    "\n",
    "# ~ 1s not received map, ~ 2-4s in map ~ 4.5-21s in shuffle \n",
    "# ~ 21.5s before reduce (no reduce task created), ~ 22s job completes\n",
    "time.sleep(3)\n",
    "\n",
    "# This is shell\n",
    "!docker kill a140e0bbeaf1 b09d2243f538 9e79739d768c 2b8234e85d64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60010b25-815a-44e4-be26-e62dfd28b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198b3fc-a400-49e1-a0d2-4b473697f4e0",
   "metadata": {},
   "source": [
    "We have now killed the 4 workers. Let's take a look at the state of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239b5a5-b298-4747-87fa-fc5760c8eb94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ca702-4df2-4ba2-897f-fa5414134d73",
   "metadata": {},
   "source": [
    "### Kill the master handling the job\n",
    "\n",
    "Observe that our cluster is currently bereft of workers, thus bringing the computation to a standstill. But we're not stopping there. Let's intensify this scenario further. We'll seek out the master overseeing the job and kill him. In doing so, we'll bring our system to its most fundamental state required to test our fault-tolerance guarantees - that is, maintaining at least one surviving master in the midst of chaos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169ba49-fb09-4d41-be2b-f7fd435e25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker kill 4d2517722e41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168737c1-ae38-4efa-8a8b-e342a9de62f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd9cac-caf0-4492-9c89-f38a2ab3ffdd",
   "metadata": {},
   "source": [
    "Notice that all the *responsibilities* of the dead master have transfered to the last surviving master (dead *worker* tasks and the job). For now, our system is in a bit of a freeze. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaaa9b7-7267-43a4-8cbc-8aac9373170c",
   "metadata": {},
   "source": [
    "### Scale the system\n",
    "\n",
    "Let's jumpstart the system by scaling it and get the computation back on track. We will add 10 workers to the system so the computation terminates quickly (remember that we passed `requested_n_workers` as `None` - use as many workers as possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101a14d-fbd7-4af1-a2f9-fef141c02798",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(n_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0c8e7-ec52-4d7d-ae85-c20c2812e2ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f91f7-5ce6-4be7-bdbc-6a9e3807f3af",
   "metadata": {},
   "source": [
    "### Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1f2c9-384d-4d8e-bad4-4c5f563c36c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.shutdown_cluster(cleanup=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mapreduce]",
   "language": "python",
   "name": "conda-env-mapreduce-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
