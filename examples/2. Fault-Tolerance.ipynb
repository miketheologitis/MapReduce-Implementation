{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c51c7b9-97d5-43ad-a264-80de500adec0",
   "metadata": {},
   "source": [
    "## Fault-Tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c3084-0a37-4eb6-af60-5b03d70fa739",
   "metadata": {},
   "source": [
    "One of the most important aspects of the MapReduce distributed system is fault-tolerance.\n",
    "\n",
    "If <ins>at all times at least one</ins> *master* service is alive, we guarantee fault tolerance for the following scenarios:\n",
    "1. *Worker* failures at any time.\n",
    "2. *Master* failures at any time.\n",
    "\n",
    "Our system not only guarantees fault-tolerance, but also that the computations in the event of *worker*, *master* failures will continue exactly where they left off as if nothing bad has happened. No recomputation will take place if not necessary. \n",
    "\n",
    "This notebook aims to simulate an extreme crisis situation in our MapReduce system: a perfect storm. Imagine a scenario where all the workers, in the midst of executing a MapReduce job, abruptly fail. As if this isn't catastrophic enough, the master responsible for coordinating that very job also shuts down unexpectedly, leaving a lone master as the sole survivor in our distributed system.\n",
    "\n",
    "Note: Addressing *worker* failures alone was comparatively simple. Likewise, overcoming *master* failures presented its unique challenges, that forced us to revise certain parts of our system. However, managing the simultaneous failures of both *workers* and *masters* - especially within the same job - has been an entirely different level of complexity. This scenario necessitates an extremely robust and meticulous system implementation. There are numerous intricate edge-cases that open the door for potential race condition issues. The system must not only handle failures independently but also efficiently coordinate and synchronize their concurrent occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c41753-36d9-45c9-88b6-1abda146f571",
   "metadata": {},
   "source": [
    "### Authenticate\n",
    "\n",
    "Use the `Auth` in-between interface for fast authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb06e9e2-313f-4c95-b235-c7fc4be12bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreduce.authentication.auth import Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39643d7d-6aa3-4e01-a3c7-8291090d3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = Auth(username='admin', password='admin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1eb605d1-94e6-40f1-a10c-e6c404b64b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth.is_authenticated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b495957-ee7e-4d81-a8c5-8c94863b8d44",
   "metadata": {},
   "source": [
    "### Initialize the docker-compose network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d03cd190-8651-4659-b6f6-488da30aa38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreduce.cluster.local_cluster import LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b94bc63-d40f-4b74-aed9-b8760941dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(\n",
    "    auth=auth,\n",
    "    n_workers=4,\n",
    "    n_masters=2,\n",
    "    initialize=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613d63f-67bf-44cc-be2d-0f29069351f2",
   "metadata": {},
   "source": [
    "As in the previous notebook, let's assume that our objective is to count how many times each character appears in the a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e426411-51ab-41a1-9a86-772c963c48fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_func(data):\n",
    "    result = []\n",
    "    for string in data:\n",
    "        for char in string:\n",
    "            result.append((char, 1))\n",
    "    return result\n",
    "\n",
    "def reduce_func(data):\n",
    "    return sum(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d37652-592f-48bc-8522-4c2fc46f0146",
   "metadata": {},
   "source": [
    "Create some reasonable amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e277cff9-b4d7-4d31-b386-6cf17073d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_string(str_len):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for _ in range(str_len))\n",
    "\n",
    "def generate_random_string_list(n, str_len):\n",
    "    return [generate_random_string(str_len) for _ in range(n)]\n",
    "\n",
    "data = generate_random_string_list(n=500_000, str_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97091033-6f84-4515-90fb-9486d5d20fef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wqiweuzzpwcvtvanlsve',\n",
       " 'dqltqatyejlsqcqwrnow',\n",
       " 'nnggnimkcdeqddcqurpo',\n",
       " 'rwelramzkrbvppoovnig',\n",
       " 'yzbrnkaqpnlvugjxnhho',\n",
       " 'tgsjtubksqzefttgwnhe',\n",
       " 'eufooahdkkpdhnzksiqv',\n",
       " 'zygbtgxuqisvgarrawqp',\n",
       " 'wxyhkgragleecinlfbco',\n",
       " 'dkuogphgkpijqbtogany']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26265a-4ab2-46b0-bc4e-ed9d4133dc50",
   "metadata": {},
   "source": [
    "### Kill workers amidst computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c730df-3299-4cfc-8b75-9e22fdb61860",
   "metadata": {},
   "source": [
    "This part (the next one aswell) will not be entirely sequential. We have configured `docker-compose` so that the *workers* and *masters* use the *container-id* as *hostname*. Hence, grab the 4 *worker* container-ids from bellow and prepare the `docker kill` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b9b94c4-a6fd-43c6-8d92-e20d43591e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------- Zoo Masters -----------------\n",
      "Master 455251675c09 :  MasterInfo(state='nothing')\n",
      "Master 9b4a284e74be :  MasterInfo(state='nothing')\n",
      "\n",
      "----------------- Zoo Workers -----------------\n",
      "Worker c3aa3f9c75ce :  WorkerInfo(state='idle')\n",
      "Worker 113b86cfa5d5 :  WorkerInfo(state='idle')\n",
      "Worker 8d95f0c5afad :  WorkerInfo(state='idle')\n",
      "Worker 5033b9dc545b :  WorkerInfo(state='idle')\n",
      "\n",
      "----------------- Zoo Map Tasks -----------------\n",
      "\n",
      "----------------- Zoo Shuffle Tasks -----------------\n",
      "\n",
      "----------------- Zoo Reduce Tasks -----------------\n",
      "\n",
      "----------------- Zoo Jobs ---------------------\n",
      "\n",
      "\n",
      "------------- Dead Worker Tasks ---------------------\n"
     ]
    }
   ],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7706c9cd-b937-4da7-84e9-76709bf058c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.local_monitoring.print_hdfs('jobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a98a2b-b843-4ba2-8f0b-c3be42d80bc0",
   "metadata": {},
   "source": [
    "Note, if `requested_n_workers` is not provided it defaults to `None` which is translated to the underlying computation as \"use as many workers as possible\".\n",
    "\n",
    "By now, you should have replaced the `docker kill` command with the appropriate ids from above (load the gun). We are ready to submit the job and kill the 4 workers on the spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f0b3824-1e97-465e-8935-a3c89e65296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c3aa3f9c75ce\n",
      "113b86cfa5d5\n",
      "8d95f0c5afad\n",
      "5033b9dc545b\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "future = cluster.mapreduce(\n",
    "    data=data, \n",
    "    map_func=map_func, \n",
    "    reduce_func=reduce_func\n",
    ")\n",
    "\n",
    "# ------- Kill workers on specific point in the MapReduce execution -----\n",
    "\n",
    "# Get the Zookeeper client\n",
    "zk_client = cluster.get_zk_client()\n",
    "\n",
    "# Put `/reduce_tasks` if you want to kill on reduce, `/shuffle_tasks` on shuffle\n",
    "kill_workers_amidst = '/map_tasks'\n",
    "\n",
    "def tasks_received(file_tasks):\n",
    "    return all(zk_client.get(f'{file_tasks}/{file}').received for file in zk_client.zk.get_children(file_tasks))\n",
    "        \n",
    "while not zk_client.zk.get_children(kill_workers_amidst) or not tasks_received(kill_workers_amidst):\n",
    "    time.sleep(0.05)\n",
    "\n",
    "# ------- Kill workers now -----\n",
    "\n",
    "# This is shell (REPLACE from above)\n",
    "!docker kill c3aa3f9c75ce 113b86cfa5d5 8d95f0c5afad 5033b9dc545b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60010b25-815a-44e4-be26-e62dfd28b9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x7f523a069110 state=running>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198b3fc-a400-49e1-a0d2-4b473697f4e0",
   "metadata": {},
   "source": [
    "We have now killed the 4 workers. Let's take a look at the state of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f239b5a5-b298-4747-87fa-fc5760c8eb94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------- Zoo Masters -----------------\n",
      "Master 455251675c09 :  MasterInfo(state='nothing')\n",
      "Master 9b4a284e74be :  MasterInfo(state='nothing')\n",
      "\n",
      "----------------- Zoo Workers -----------------\n",
      "\n",
      "----------------- Zoo Map Tasks -----------------\n",
      "Task 0_0 :  Task(state='in-progress', worker_hostname='None', received=True)\n",
      "Task 0_1 :  Task(state='in-progress', worker_hostname='None', received=True)\n",
      "Task 0_2 :  Task(state='in-progress', worker_hostname='None', received=True)\n",
      "Task 0_3 :  Task(state='in-progress', worker_hostname='None', received=True)\n",
      "\n",
      "----------------- Zoo Shuffle Tasks -----------------\n",
      "\n",
      "----------------- Zoo Reduce Tasks -----------------\n",
      "\n",
      "----------------- Zoo Jobs ---------------------\n",
      "Job 0 :  Job(state='in-progress', requested_n_workers=None, master_hostname='455251675c09')\n",
      "\n",
      "\n",
      "------------- Dead Worker Tasks ---------------------\n",
      "Dead Worker Task 0_0 :  DeadTask(state='in-progress', master_hostname='455251675c09', task_type='map')\n",
      "Dead Worker Task 0_1 :  DeadTask(state='in-progress', master_hostname='455251675c09', task_type='map')\n",
      "Dead Worker Task 0_2 :  DeadTask(state='in-progress', master_hostname='455251675c09', task_type='map')\n",
      "Dead Worker Task 0_3 :  DeadTask(state='in-progress', master_hostname='9b4a284e74be', task_type='map')\n"
     ]
    }
   ],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ca702-4df2-4ba2-897f-fa5414134d73",
   "metadata": {},
   "source": [
    "### Kill the master handling the job\n",
    "\n",
    "Observe that our cluster is currently bereft of workers, thus bringing the computation to a standstill. But we're not stopping there. Let's intensify this scenario further. We'll seek out the master overseeing the job and kill him. In doing so, we'll bring our system to its most fundamental state required to test our fault-tolerance guarantees - that is, maintaining at least one surviving master in the midst of chaos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a169ba49-fb09-4d41-be2b-f7fd435e25c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455251675c09\n"
     ]
    }
   ],
   "source": [
    "# REPLACE from above\n",
    "!docker kill 455251675c09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "168737c1-ae38-4efa-8a8b-e342a9de62f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------- Zoo Masters -----------------\n",
      "Master 9b4a284e74be :  MasterInfo(state='nothing')\n",
      "\n",
      "----------------- Zoo Workers -----------------\n",
      "\n",
      "----------------- Zoo Map Tasks -----------------\n",
      "Task 0_0 :  Task(state='in-progress', worker_hostname='None', received=True)\n",
      "Task 0_1 :  Task(state='in-progress', worker_hostname='None', received=True)\n",
      "Task 0_2 :  Task(state='in-progress', worker_hostname='None', received=True)\n",
      "Task 0_3 :  Task(state='in-progress', worker_hostname='None', received=True)\n",
      "\n",
      "----------------- Zoo Shuffle Tasks -----------------\n",
      "\n",
      "----------------- Zoo Reduce Tasks -----------------\n",
      "\n",
      "----------------- Zoo Jobs ---------------------\n",
      "Job 0 :  Job(state='in-progress', requested_n_workers=None, master_hostname='9b4a284e74be')\n",
      "\n",
      "\n",
      "------------- Dead Worker Tasks ---------------------\n",
      "Dead Worker Task 0_0 :  DeadTask(state='in-progress', master_hostname='9b4a284e74be', task_type='map')\n",
      "Dead Worker Task 0_1 :  DeadTask(state='in-progress', master_hostname='9b4a284e74be', task_type='map')\n",
      "Dead Worker Task 0_2 :  DeadTask(state='in-progress', master_hostname='9b4a284e74be', task_type='map')\n",
      "Dead Worker Task 0_3 :  DeadTask(state='in-progress', master_hostname='9b4a284e74be', task_type='map')\n"
     ]
    }
   ],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd9cac-caf0-4492-9c89-f38a2ab3ffdd",
   "metadata": {},
   "source": [
    "Notice that all the *responsibilities* of the dead master have transfered to the last surviving master (dead *worker* tasks and the job). For now, our system is in a bit of a freeze. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaaa9b7-7267-43a4-8cbc-8aac9373170c",
   "metadata": {},
   "source": [
    "### Scale the system\n",
    "\n",
    "Let's jumpstart the system by scaling it and get the computation back on track. We will add 10 workers to the system so the computation terminates quickly (remember that we passed `requested_n_workers` as `None` - use as many workers as possible).\n",
    "\n",
    "Note: We do not have to pass `n_masters=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f101a14d-fbd7-4af1-a2f9-fef141c02798",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(n_masters=2, n_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ebf0c8e7-ec52-4d7d-ae85-c20c2812e2ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------- Zoo Masters -----------------\n",
      "Master 455251675c09 :  MasterInfo(state='nothing')\n",
      "Master 9b4a284e74be :  MasterInfo(state='nothing')\n",
      "\n",
      "----------------- Zoo Workers -----------------\n",
      "Worker c3aa3f9c75ce :  WorkerInfo(state='idle')\n",
      "Worker 21f2333b30e5 :  WorkerInfo(state='idle')\n",
      "Worker 3f4f12cc3a83 :  WorkerInfo(state='idle')\n",
      "Worker 113b86cfa5d5 :  WorkerInfo(state='idle')\n",
      "Worker ee9bcfbcdb52 :  WorkerInfo(state='idle')\n",
      "Worker a8ae1bcf033b :  WorkerInfo(state='idle')\n",
      "Worker c6e634cb5e76 :  WorkerInfo(state='idle')\n",
      "Worker 4e486cfab832 :  WorkerInfo(state='idle')\n",
      "Worker 8d95f0c5afad :  WorkerInfo(state='idle')\n",
      "Worker 5033b9dc545b :  WorkerInfo(state='idle')\n",
      "\n",
      "----------------- Zoo Map Tasks -----------------\n",
      "Task 0_0 :  Task(state='completed', worker_hostname='113b86cfa5d5', received=True)\n",
      "Task 0_1 :  Task(state='completed', worker_hostname='21f2333b30e5', received=True)\n",
      "Task 0_2 :  Task(state='completed', worker_hostname='3f4f12cc3a83', received=True)\n",
      "Task 0_3 :  Task(state='completed', worker_hostname='c3aa3f9c75ce', received=True)\n",
      "\n",
      "----------------- Zoo Shuffle Tasks -----------------\n",
      "Task 0 :  Task(state='completed', worker_hostname='c3aa3f9c75ce', received=True)\n",
      "\n",
      "----------------- Zoo Reduce Tasks -----------------\n",
      "Task 0_24_25 :  Task(state='completed', worker_hostname='5033b9dc545b', received=True)\n",
      "Task 0_0_1_2 :  Task(state='completed', worker_hostname='c3aa3f9c75ce', received=True)\n",
      "Task 0_22_23 :  Task(state='completed', worker_hostname='8d95f0c5afad', received=True)\n",
      "Task 0_12_13_14 :  Task(state='completed', worker_hostname='ee9bcfbcdb52', received=True)\n",
      "Task 0_15_16_17 :  Task(state='completed', worker_hostname='a8ae1bcf033b', received=True)\n",
      "Task 0_6_7_8 :  Task(state='completed', worker_hostname='3f4f12cc3a83', received=True)\n",
      "Task 0_18_19 :  Task(state='completed', worker_hostname='c6e634cb5e76', received=True)\n",
      "Task 0_9_10_11 :  Task(state='completed', worker_hostname='113b86cfa5d5', received=True)\n",
      "Task 0_3_4_5 :  Task(state='completed', worker_hostname='21f2333b30e5', received=True)\n",
      "Task 0_20_21 :  Task(state='completed', worker_hostname='4e486cfab832', received=True)\n",
      "\n",
      "----------------- Zoo Jobs ---------------------\n",
      "Job 0 :  Job(state='completed', requested_n_workers=None, master_hostname='9b4a284e74be')\n",
      "\n",
      "\n",
      "------------- Dead Worker Tasks ---------------------\n",
      "Dead Worker Task 0_0 :  DeadTask(state='completed', master_hostname='9b4a284e74be', task_type='map')\n",
      "Dead Worker Task 0_1 :  DeadTask(state='completed', master_hostname='9b4a284e74be', task_type='map')\n",
      "Dead Worker Task 0_2 :  DeadTask(state='completed', master_hostname='9b4a284e74be', task_type='map')\n",
      "Dead Worker Task 0_3 :  DeadTask(state='completed', master_hostname='9b4a284e74be', task_type='map')\n"
     ]
    }
   ],
   "source": [
    "cluster.local_monitoring.print_zoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e8b3e15-0902-4eee-b423-dceefe7a2648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 384908),\n",
       " ('b', 384710),\n",
       " ('c', 384655),\n",
       " ('m', 385397),\n",
       " ('n', 384379),\n",
       " ('o', 384750),\n",
       " ('p', 384546),\n",
       " ('q', 383329),\n",
       " ('r', 385062),\n",
       " ('s', 384774),\n",
       " ('t', 384563),\n",
       " ('u', 384552),\n",
       " ('v', 384386),\n",
       " ('w', 384494),\n",
       " ('x', 384269),\n",
       " ('y', 384779),\n",
       " ('z', 383976),\n",
       " ('d', 384408),\n",
       " ('e', 384083),\n",
       " ('f', 384732),\n",
       " ('g', 384015),\n",
       " ('h', 384564),\n",
       " ('i', 385879),\n",
       " ('j', 384868),\n",
       " ('k', 384441),\n",
       " ('l', 385481)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f91f7-5ce6-4be7-bdbc-6a9e3807f3af",
   "metadata": {},
   "source": [
    "### Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5be1f2c9-384d-4d8e-bad4-4c5f563c36c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster.shutdown_cluster(cleanup=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mapreduce]",
   "language": "python",
   "name": "conda-env-mapreduce-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
